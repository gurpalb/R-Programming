setwd("C:/Users/gbisra.stu/Desktop/COMM581_A4")
mydata <- read.csv("Yield_and_temperature.csv", header=TRUE)
View(mydata)
mydata$temperature.squared <- (mydata$temperature)^2 # create a new column in your dataframe with transformed values of the x-variable
View(mydata)
plot(yield ~ temperature, data = mydata, pch = 16)
z2 <- lm(yield ~ temperature + temperature.squared, data=mydata) # fit a multiple linear regression model with the original x-variable and the transformed x-variable
# plot residuals
resid1 <- resid(z1)
predict1 <- predict(z1)
# plot residuals
resid1 <- resid(z2)
predict1 <- predict(z2)
# plot residuals
plot(resid1 ~ predict1, data = mydata, pch = 16)
abline(0,0, lty=2)
hist(resid2)
hist(resid2)
hist(resid1)
plot(z2)
predict1 <- predict(z2)
mydata$predict1 <- predict(z2)
plot(yield ~ predict1, data = mydata, pch = 16)
# not Q-Q plot, but looking for same re
abline(0,1)
hist(resid1)
mydata$resid1 <- resid(z2)
plot(yield ~ resid1, data = mydata, pch = 16)
plot(resid1 ~ predict1, data = mydata, pch = 16)
library(nortest)
install.packages("nortest")
library(nortest)
shapiro.test(resid1)
ad.test(resid2)
cvm.test(resid2)
lillie.test(resid2)
library(nortest)
shapiro.test(resid1)
ad.test(resid1)
cvm.test(resid1)
lillie.test(resid1)
View(mydata)
qqnorm(resid1)
qqline(resid1, main = "Normal Q-Q plot of residuals", col = "red")
anova(z2)
summary(z2)
# Find the prediction intervals
xnew <- seq(min(mydata$temperature), max(mydata$temperature), length.out = 100)
# create a new vector with 100 different points ranging from your minimum x-value to your maximum x-value
xnew <- as.data.frame(xnew) # convert this to a dataframe so that you can add additional columns
# because now we have multiple parameters, temperature and temperature.squared
names(xnew)[1] <- c("temperature")
# rename the first column to match your original x-variable, I called it temperature before in the code, so I will     give it the same name now. This makes it easy for R to match up the new data with the variables that are in the        model
# names must match!
xnew$temperature.squared <- (xnew$temperature)^2
# create a second column in your dataframe with temperature squared. Again, give this the same variable name it had     before in the code
xnew # This is a good point to view your new data to check that everything is working properly
ynew.ci <- data.frame(predict(z2, newdata = data.frame(xnew), interval = "prediction", level = 0.95))
# R will calculate the predicted values and  prediction intervals for all the different new x values that you have     provided
ynew.ci
new.values <- cbind(xnew,ynew.ci)
# combine the dataframe  with the new x-values and the dataframe with the predicted y-values and prediction            intervals
new.values
# Check that all your columns are what you would expect them to be
plot(mydada$yield~mydata$temperature)
lines(new.values$fit.back ~ new.values$xnew.back, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr.back <- new.values$xnew.back, lty = 2, col = "blue")
lines(new.values$upr.back <- new.values$xnew.back, lty = 2, col = "blue")
plot(mydata$yield~mydata$temperature)
lines(new.values$fit.back ~ new.values$xnew.back, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr.back <- new.values$xnew.back, lty = 2, col = "blue")
lines(new.values$upr.back <- new.values$xnew.back, lty = 2, col = "blue")
# Find the prediction intervals
xnew <- seq(min(mydata$temperature), max(mydata$temperature), length.out = 100)
# create a new vector with 100 different points ranging from your minimum x-value to your maximum x-value
xnew <- as.data.frame(xnew) # convert this to a dataframe so that you can add additional columns
# because now we have multiple parameters, temperature and temperature.squared
names(xnew)[1] <- c("temperature")
# rename the first column to match your original x-variable, I called it temperature before in the code, so I will     give it the same name now. This makes it easy for R to match up the new data with the variables that are in the        model
# names must match!
xnew$temperature.squared <- (xnew$temperature)^2
# create a second column in your dataframe with temperature squared. Again, give this the same variable name it had     before in the code
xnew # This is a good point to view your new data to check that everything is working properly
ynew.ci <- data.frame(predict(z2, newdata = data.frame(xnew), interval = "prediction", level = 0.95))
# R will calculate the predicted values and  prediction intervals for all the different new x values that you have     provided
ynew.ci
new.values <- cbind(xnew,ynew.ci)
# combine the dataframe  with the new x-values and the dataframe with the predicted y-values and prediction            intervals
new.values
# Check that all your columns are what you would expect them to be
plot(mydata$yield~mydata$temperature)
lines(new.values$fit.back ~ new.values$xnew.back, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr.back <- new.values$xnew.back, lty = 2, col = "blue")
lines(new.values$upr.back <- new.values$xnew.back, lty = 2, col = "blue")
plot(mydata$yield~mydata$temperature)
lines(new.values$fit ~ new.values$temperature, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr <- new.values$temperature, lty = 2, col = "blue")
lines(new.values$upr <- new.values$temperature, lty = 2, col = "blue")
# Find the prediction intervals
xnew <- seq(min(mydata$temperature), max(mydata$temperature), length.out = 100)
# create a new vector with 100 different points ranging from your minimum x-value to your maximum x-value
xnew <- as.data.frame(xnew) # convert this to a dataframe so that you can add additional columns
# because now we have multiple parameters, temperature and temperature.squared
names(xnew)[1] <- c("temperature")
# rename the first column to match your original x-variable, I called it temperature before in the code, so I will     give it the same name now. This makes it easy for R to match up the new data with the variables that are in the        model
# names must match!
xnew$temperature.squared <- (xnew$temperature)^2
# create a second column in your dataframe with temperature squared. Again, give this the same variable name it had     before in the code
xnew # This is a good point to view your new data to check that everything is working properly
ynew.ci <- data.frame(predict(z2, newdata = data.frame(xnew), interval = "prediction", level = 0.95))
# R will calculate the predicted values and  prediction intervals for all the different new x values that you have     provided
ynew.ci
new.values <- cbind(xnew,ynew.ci)
# combine the dataframe  with the new x-values and the dataframe with the predicted y-values and prediction            intervals
new.values
# Check that all your columns are what you would expect them to be
plot(mydata$yield~mydata$temperature)
lines(new.values$fit ~ new.values$temperature, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr ~ new.values$temperature, lty = 2, col = "blue")
lines(new.values$upr ~ new.values$temperature, lty = 2, col = "blue")
plot(mydata$yield~mydata$temperature, pch = 16)
lines(new.values$fit ~ new.values$temperature, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr ~ new.values$temperature, lty = 2, col = "blue")
lines(new.values$upr ~ new.values$temperature, lty = 2, col = "blue")
plot(mydata$yield~mydata$temperature, pch = 16, ylim=c(125,170))
lines(new.values$fit ~ new.values$temperature, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr ~ new.values$temperature, lty = 2, col = "blue")
lines(new.values$upr ~ new.values$temperature, lty = 2, col = "blue")
plot(mydata$yield~mydata$temperature, pch = 16, ylim=c(125,160))
lines(new.values$fit ~ new.values$temperature, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr ~ new.values$temperature, lty = 2, col = "blue")
lines(new.values$upr ~ new.values$temperature, lty = 2, col = "blue")
summary(z2)
### Question 8 ###
confint(z2, level=0.95) # get the 95% confidence intervals for the co-efficients
mydata[which.max(mydata$predict1), ]
View(ynew.ci)
ynew.ci[which.max(ynew.ci$Fit), ]
View(ynew.ci)
ynew.ci[which.max(ynew.ci$fit), ]
View(xnew)
mydata <- read.csv("Yield_and_temperature.csv", header=TRUE)
# import data from csv, and declaring header row at top
str(mydata)     # Observe structure of data frame which has 40 rows, 3 columns
plot(yield ~ temperature, data = mydata, pch = 16, main = "Manufacturing Yield is Nonlinear Function of Temperature", xlab="Temperature", ylab="Yield")
# see quadratic relationship, therefore, transform x
# denote x1 = first variable
plot(yield ~ temperature, data = mydata, col = "blue", pch = 16, main = "Manufacturing Yield is Nonlinear Function of Temperature", xlab="Temperature", ylab="Yield")
# see quadratic relationship, therefore, tra
View(mydata)
# Determine outliers by plotting a line through data of locally weighted averaged lines where I set the delta value (i.e. want delta as low as possible)
lines(lowess(mydata$temperature, mydata$yield, delta=0.1), col="red")
# create a new column in your dataframe with transformed values of the x-variable
mydata$temperature.squared <- (mydata$temperature)^2    # must do as separate step, because R not know x or x^2 related
# denote: temperature^2 = x2
# create model, of y then list x variables
z2 <- lm(yield ~ temperature + temperature.squared, data=mydata)
# fit a multiple linear regression model with the original x-variable and the transformed x-variable
# New dataset --> temperature, temperature.squared
# plot residuals
plot(resid1 ~ predict1, data = mydata, pch = 16)
abline(0,0, lty=2)
# Check if relationship is linear
# Compute residuals of object z1 (linear fit of sales vs. number of employees)
resid1 <- resid(z2)
# Calculate predicted y_hat values
predict1 <- predict(z2)
# plot residuals
plot(resid1 ~ predict1, data = mydata, pch = 16)
abline(0,0, lty=2)
# Residual plot for model based on original units
plot(resid1 ~ predict1, pch=16, main = "Residuals of Predicted Model", xlab="Predicted Yield Values", ylab="Errors of Residuals of Yield")
# Add line Residuals = 0
abline(0, 0, lty=2)
# create a new column in your dataframe with transformed values of the x-variable
mydata$temperature.squared <- (mydata$temperature)^2    # must do as separate step, because R not know x or x^2 related
# denote: temperature^2 = x2
# create model, of y then list x variables
z2 <- lm(yield ~ temperature + temperature.squared, data=mydata)
# fit a multiple linear regression model with the original x-variable and the transformed x-variable
# New dataset --> temperature, temperature.squared
# Check if relationship is linear
# Compute residuals of object z1 (linear fit of sales vs. number of employees)
resid1 <- resid(z2)
# Calculate predicted y_hat values
predict1 <- predict(z2)
# Residual plot for model based on original units
plot(resid1 ~ predict1, pch=16, main = "Residuals of Predicted Model", xlab="Predicted Yield Values", ylab="Errors of Residuals of Yield")
# Add line Residuals = 0
abline(0, 0, lty=2)
View(mydata)
mydata$predict1 <- predict(z2)
mydata$resid1 <- resid(z2)
plot(yield ~ predict1, data = mydata, pch = 16)
# not Q-Q plot, but looking at how well the model matches the data
abline(0,1)
qqnorm(resid1)
qqline(resid1, main = "Normal Q-Q plot of residuals", col = "red")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-5, 5, by=0.2), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-5, 5, by=1), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-5, 5, by=11), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-5, 5, by=2), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-5, 5, by=1.5), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-5, 5, by=0.8), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-5, 4, by=0.8), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-5, 4, by=0.8), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
mydata$predict1 <- predict(z2)
mydata$resid1 <- resid(z2)
plot(yield ~ predict1, data = mydata, pch = 16)
# not Q-Q plot, but looking at how well the model matches the data
abline(0,1)
qqnorm(resid1)
qqline(resid1, main = "Normal Q-Q plot of residuals", col = "red")
mydata$predict1 <- predict(z2)
mydata$resid1 <- resid(z2)
plot(yield ~ predict1, data = mydata, pch = 16)
# not Q-Q plot, but looking at how well the model matches the data
abline(0,1)
plot(yield ~ predict1, data = mydata, pch = 16, col = "blue", main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# not Q-Q plot, but looking at how well the model matches the data
abline(0,1)
abline(0,1,lty=2)
mydata$predict1 <- predict(z2)
mydata$resid1 <- resid(z2)
plot(yield ~ predict1, data = mydata, pch = 16, col = "blue", main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# not Q-Q plot, but looking at how well the model matches the data
abline(0,1,lty=2)
# Plot yield vs. y_hat
mydata$predict1 <- predict(z2)
mydata$resid1 <- resid(z2)
plot(yield ~ predict1, data = mydata, pch = 16, col = "blue", main = "Yield Values Similar to Predicted Values", xlab="Predicted Yield", ylab="Yield")
# not Q-Q plot, but looking at how well the model matches the data
abline(0,1,lty=2)
### Write the ANOVA table for this model showing each component of variation (variable 1, variable 2, error, total), its associated df, sum of squares and mean squares. (3 marks)
anova(z2)
# double check addition with summary(z2)
summary(z2)
summary(z2)
confint(z2, level=0.95) # get the 95% confidence intervals for the co-efficients
# Find the prediction intervals
xnew <- seq(min(mydata$temperature), max(mydata$temperature), length.out = 100)
# create a new vector with 100 different points ranging from your minimum x-value to your maximum x-value
xnew <- as.data.frame(xnew) # convert this to a dataframe so that you can add additional columns
# because now we have multiple parameters, temperature and temperature.squared
names(xnew)[1] <- c("temperature")
# rename the first column to match your original x-variable, I called it temperature before in the code, so I will     give it the same name now. This makes it easy for R to match up the new data with the variables that are in the        model
# names must match!
xnew$temperature.squared <- (xnew$temperature)^2
# create a second column in your dataframe with temperature squared. Again, give this the same variable name it had     before in the code
xnew # This is a good point to view your new data to check that everything is working properly
ynew.ci <- data.frame(predict(z2, newdata = data.frame(xnew), interval = "prediction", level = 0.95))
# R will calculate the predicted values and  prediction intervals for all the different new x values that you have     provided
ynew.ci
new.values <- cbind(xnew,ynew.ci)
# combine the dataframe  with the new x-values and the dataframe with the predicted y-values and prediction            intervals
new.values
# Check that all your columns are what you would expect them to be
### to find max in data frame
ynew.ci[which.max(ynew.ci$fit), ]
# then it's corresponds to row 50 in xnew is 723....
### Question 12 -------------------------------------------------------------------
### Create a plot of the original data (yield vs. temperature) including the line of best fit and lines for the prediction intervals.
plot(mydata$yield~mydata$temperature, pch = 16, ylim=c(125,160))
lines(new.values$fit ~ new.values$temperature, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr ~ new.values$temperature, lty = 2, col = "blue")
lines(new.values$upr ~ new.values$temperature, lty = 2, col = "blue")
plot(mydata$yield~mydata$temperature, pch = 16, ylim=c(125,160), main = "Manufacturing Yield is Nonlinear Function of Temperature", xlab="Temperature", ylab="Yield")
lines(new.values$fit ~ new.values$temperature, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr ~ new.values$temperature, lty = 2, col = "blue")
lines(new.values$upr ~ new.values$temperature, lty = 2, col = "blue")
plot(mydata$yield~mydata$temperature, pch = 16, ylim=c(125,160), main = "Manufacturing Yield as Function of Temperature with Best Fit", xlab="Temperature", ylab="Yield")
lines(new.values$fit ~ new.values$temperature, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr ~ new.values$temperature, lty = 2, col = "blue")
lines(new.values$upr ~ new.values$temperature, lty = 2, col = "blue")
plot(mydata$yield~mydata$temperature, pch = 16, ylim=c(125,160), main = "Manufacturing Yield as Function of Temperature \n with Line of Best Fit", xlab="Temperature", ylab="Yield")
lines(new.values$fit ~ new.values$temperature, lty=1, col = "red")
# this looks different because we we are using the columns from the data frame instead of vectors
lines(new.values$lwr ~ new.values$temperature, lty = 2, col = "blue")
lines(new.values$upr ~ new.values$temperature, lty = 2, col = "blue")
### to find max in data frame
ynew.ci[which.max(ynew.ci$fit), ]
SSY <- sum((mydata$yield - mean(mydata$yield))^2)
SSY
ynew.ci[which.max(ynew.ci$fit), ]
### to find max in data frame
xnew.ci[which.max(xnew.ci$fit), ]
View(xnew)
### to find max in data frame
xnew.ci[which.max(xnew.ci$temperature), ]
ynew.ci[which.max(ynew.ci$fit), ]
View(xnew)
xnew[which.max(xnew$temperature), ]
ynew.ci[which.max(ynew.ci$fit), ]
View(xnew)
View(new.values)
View(ynew.ci)
View(mydata)
View(new.values)
summary(new.values)
View(new.values)
x11 = predict(new.values, new.values$fit,
interval = c("none", "confidence", "prediction"),
level = 0.95)
View(new.values)
x11 = predict(z2, new.values(fit=154.0416),
interval = "prediction",
level = 0.95)
x11 = predict(new.values, fit=154.0416),
interval = "prediction",
level = 0.95)
x11 = predict(new.values, new.values(fit=154.0416),
interval = "prediction",
level = 0.95)
x11 = predict(z2, data.frame(fit=154.0416),
interval = "prediction",
level = 0.95)
x11 = predict(z2, data.frame(temperature = 723.7374, fit=154.0416),interval = "prediction", level = 0.95)
x11 = predict(z2, data.frame(temperature = 723.7374, temperature.squared=523795.8, fit=154.0416),interval = "prediction", level = 0.95)
View(x11)
predict(z2, data.frame(temperature = 723.7374, temperature.squared=523795.8, fit=154.0416),interval = "prediction", level = 0.95)
SSX <- sum((mydata$temperature - mean(mydata$temperature))^2)
SSX
mean(mydata$temperature)
sqrt(((((723.7374 -725)^2)/68750)+(1/11)+1)*3.63)
24.70786+(2.306*(1.989996))
154.0416+(2.306*(1.989996))
154.0416-(2.306*(1.989996))
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-5, 4, by=2), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-5, 4, by=1.5), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-4, 3.5, by=1.5), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
# Look at the histogram to see whether the residuals are normally distributed
hist(resid1, breaks = seq(-4, 5, by=1.5), main = "Histogram of Predicted Model", xlab="Errors of Residuals of Yield", ylab="Frequency")
